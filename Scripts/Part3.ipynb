{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis System using HMM (Continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new function for processing unlabelled data (test data for our predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    f = open(filename, 'r', encoding=\"utf8\")\n",
    "    lines = f.readlines()\n",
    "    datas = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            datas.append(lines[start:i])\n",
    "            start = i+1\n",
    "        lines[i] = lines[i].replace('\\n','')\n",
    "        lines[i] = tuple(lines[i].split(' '))\n",
    "        \n",
    "    # check formatting\n",
    "#     for i in range(len(datas)):\n",
    "#         for j in range(len(datas[i])):\n",
    "#             assert len(datas[i][j])==2\n",
    "            \n",
    "    \n",
    "    for i in range(len(datas)):\n",
    "        data = datas[i]\n",
    "        x = [word[0] for word in data]\n",
    "        y = [word[1] for word in data]\n",
    "        datas[i] = [x,y]\n",
    "    \n",
    "    all_x = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_x.append(datas[i][0][j])\n",
    "    x_set = frozenset(all_x)\n",
    "    \n",
    "    all_y = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_y.append(datas[i][1][j])\n",
    "    y_set = frozenset(all_y)\n",
    "    \n",
    "    return dict(data=datas,x_set=x_set,y_set=y_set)\n",
    "\n",
    "def get_unlabelled_data(filename):\n",
    "    f = open(filename, 'r', encoding=\"utf8\")\n",
    "    lines = f.readlines()\n",
    "    datas = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            datas.append(lines[start:i])\n",
    "            start = i+1\n",
    "        lines[i] = lines[i].replace('\\n','')\n",
    "            \n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5 pts) Write a function that estimates the transition parameters from the training set using MLE\n",
    "\n",
    "    q(y_i|y_i-1) = Count(y_i-1, y_i) / Count(y_i-1)\n",
    "    \n",
    "*The following special cases are also considered: q(STOP|y_n) and q(y_1|START).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = get_data('EN/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transmission_params(data_dict):\n",
    "    from_y = ['START'] + list(data_dict['y_set']) \n",
    "    to_y = list(data_dict['y_set']) + ['STOP']\n",
    "    l = len(from_y)\n",
    "    transmission_count = pd.DataFrame(np.zeros((l,l)),index=from_y,columns=to_y)\n",
    "\n",
    "    datas = data_dict['data']\n",
    "    for instance in datas:\n",
    "        x_vector,y_vector = instance\n",
    "        length = len(y_vector)\n",
    "        for i in range(length+1):\n",
    "            if i == 0 :\n",
    "                transmission_count.loc['START',y_vector[0]] += 1\n",
    "\n",
    "            elif i == length:\n",
    "                transmission_count.loc[y_vector[i-1],'STOP'] +=1\n",
    "\n",
    "            else:\n",
    "                transmission_count.loc[y_vector[i-1],y_vector[i]] += 1\n",
    "\n",
    "    y_count = transmission_count.sum(axis=1) \n",
    "    transmission_params = transmission_count\n",
    "    for i in range(len(transmission_count.index)):\n",
    "        transmission_params.iloc[i,:] /= transmission_params.iloc[i,:].sum()\n",
    "    return transmission_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the tranmission parameters that we get from using the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I-positive</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>I-negative</th>\n",
       "      <th>O</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>STOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>START</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.043780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010678</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-positive</th>\n",
       "      <td>0.406919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-positive</th>\n",
       "      <td>0.298013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.860119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.076231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209424</td>\n",
       "      <td>0.782723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            I-positive  B-neutral  B-positive  I-negative         O  \\\n",
       "START         0.000000   0.005339    0.043780    0.000000  0.940203   \n",
       "I-positive    0.406919   0.000000    0.000000    0.000000  0.584843   \n",
       "B-neutral     0.000000   0.000000    0.000000    0.000000  0.784615   \n",
       "B-positive    0.298013   0.000000    0.000000    0.000000  0.688742   \n",
       "I-negative    0.000000   0.000000    0.000000    0.398496  0.601504   \n",
       "O             0.000000   0.002269    0.046448    0.000000  0.860119   \n",
       "I-neutral     0.000000   0.000000    0.000000    0.000000  0.565217   \n",
       "B-negative    0.000000   0.000000    0.000000    0.209424  0.782723   \n",
       "\n",
       "            I-neutral  B-negative      STOP  \n",
       "START        0.000000    0.010678  0.000000  \n",
       "I-positive   0.000000    0.000000  0.008237  \n",
       "B-neutral    0.200000    0.000000  0.015385  \n",
       "B-positive   0.000000    0.000000  0.013245  \n",
       "I-negative   0.000000    0.000000  0.000000  \n",
       "O            0.000000    0.014933  0.076231  \n",
       "I-neutral    0.434783    0.000000  0.000000  \n",
       "B-negative   0.000000    0.000000  0.007853  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_params = get_transmission_params(data_dict)\n",
    "trans_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "START         1.0\n",
       "I-positive    1.0\n",
       "B-neutral     1.0\n",
       "B-positive    1.0\n",
       "I-negative    1.0\n",
       "O             1.0\n",
       "I-neutral     1.0\n",
       "B-negative    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_params.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (15 pts) Use the estimated transition and emission parameters, implement the Viterbi algorithm to compute the following (for a sentence with n words):\n",
    "\n",
    "    y*_1,..., yâˆ—_n = argmax_y1,...,yn(p)(x1,...,xn,y1,...,yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emission_counts(data_dict):\n",
    "    \"\"\"\n",
    "    returns (DataFrame,Series) \n",
    "    an emission count (y->x) DataFrame and y count Series\n",
    "    \"\"\"\n",
    "    data = data_dict['data']\n",
    "    x_set = data_dict['x_set']\n",
    "    y_set = data_dict['y_set']\n",
    "    count_em_df = pd.DataFrame(np.zeros((len(x_set),len(y_set))),index=x_set,columns=y_set)\n",
    "    count_y = pd.Series(np.zeros(len(y_set)),index=y_set)\n",
    "\n",
    "    for instance in data:\n",
    "        x_vector,y_vector = instance\n",
    "        for i in range(len(x_vector)):\n",
    "            x,y = x_vector[i],y_vector[i]\n",
    "            count_em_df.loc[x,y]+=1\n",
    "            count_y[y]+=1\n",
    "    return count_em_df,count_y\n",
    "\n",
    "def get_modified_counts(data_dict,k):\n",
    "    count_em_df,count_y = get_emission_counts(data_dict)\n",
    "    \n",
    "    counts_x = count_em_df.sum(axis=1)\n",
    "    fail = counts_x[counts_x<k]\n",
    "\n",
    "    unk = count_em_df.loc[fail.index].sum(axis=0)\n",
    "    unk.name = '#UNK#'\n",
    "   \n",
    "    modified_df = count_em_df.append(unk)\n",
    "    modified_df = modified_df.drop(fail.index, axis=0) \n",
    "    \n",
    "    return modified_df,count_y\n",
    "\n",
    "\n",
    "def get_modified_emission_params(data_dict,k=3):\n",
    "    \"\"\"\n",
    "    returns DataFrame representing conditional probabilities P(y|x)\n",
    "    \"\"\"\n",
    "    count_em_df,count_y = get_modified_counts(data_dict,k)\n",
    "    return count_em_df/count_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertibi(x_vector,trans_params,em_params):\n",
    "    \"\"\"\n",
    "    x_vector: a list of string which represent the sequence of observations\n",
    "    trans_params: a DataFrame with index from_states, columns to_states \n",
    "                  containing the transmission probabilities\n",
    "    em_params: a DataFrame with index observations, columns states which contains\n",
    "               the emission probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    states = trans_params.index.tolist()\n",
    "    states.remove('START')\n",
    "    states.remove('O')\n",
    "    states = ['O']+states\n",
    "\n",
    "    arr = np.zeros((len(states),len(x_vector))) *np.nan\n",
    "    arr2 = np.zeros((len(states),len(x_vector))) *np.nan\n",
    "    t1 = pd.DataFrame(arr,index=states,columns=x_vector)\n",
    "    t2 = pd.DataFrame(arr2,index=states,columns=x_vector)\n",
    "\n",
    "    for i in range(len(states)):\n",
    "        t1.iloc[i,0] = trans_params.loc['START',t1.index[i]] * em_params.loc[x_vector[0],t1.index[i]]\n",
    "        t2.iloc[i,0] = 0\n",
    "\n",
    "    for i in range(1,len(x_vector)):\n",
    "        for j in range(len(states)):\n",
    "            em_prob = em_params.loc[x_vector[i],states[j]] #prob of getting x_i given state j\n",
    "            maxx = None\n",
    "            argmax = None\n",
    "            for k in range(len(states)):\n",
    "                prob = t1.iloc[k,i-1] * trans_params.loc[states[k],states[j]] * em_prob\n",
    "                if maxx is None:\n",
    "                    argmax = k\n",
    "                    maxx = prob\n",
    "                    \n",
    "                elif prob>maxx:\n",
    "                    argmax = k\n",
    "                    maxx = prob\n",
    "\n",
    "            t1.iloc[j,i] = maxx\n",
    "            t2.iloc[j,i] = argmax\n",
    "\n",
    "    \n",
    "    for i in range(len(states)):\n",
    "        prob = t1.iloc[i,len(x_vector)-1]\n",
    "        t1.iloc[i,len(x_vector)-1] = t1.iloc[i,len(x_vector)-1] * trans_params.loc[states[i],'STOP']\n",
    "       \n",
    "    prediction_indx = []\n",
    "    maxx = None\n",
    "    argmax = None\n",
    "    for k in range(len(states)):\n",
    "        prob = t1.iloc[k,len(x_vector)-1]\n",
    "        if maxx is None:\n",
    "            maxx = prob\n",
    "            argmax = k\n",
    "        elif prob > maxx:\n",
    "            maxx = prob\n",
    "            argmax = k\n",
    "\n",
    "    prediction_indx.append(argmax)\n",
    "    for i in range(len(x_vector)-1,0,-1):\n",
    "        indx = t2.iloc[int(prediction_indx[0]),i]\n",
    "        prediction_indx = [indx] + prediction_indx\n",
    "\n",
    "    prediction = [states[int(i)] for i in prediction_indx]\n",
    "    return prediction\n",
    "    \n",
    "    \n",
    "def decode(fin,fout,trans_params,em_params):\n",
    "    word_bag = em_params.index.tolist()\n",
    "    unlabelled_datas = get_unlabelled_data(fin)\n",
    "    \n",
    "    results = []\n",
    "    for obs_vector in unlabelled_datas:\n",
    "        copy = []\n",
    "        for i in range(len(obs_vector)):\n",
    "            if obs_vector[i] in word_bag:\n",
    "                copy.append(obs_vector[i])\n",
    "            else:\n",
    "                copy.append('#UNK#')\n",
    "        result = vertibi(copy,trans_params,em_params)\n",
    "        assert len(result) == len(obs_vector)\n",
    "        results.append(result)\n",
    "    \n",
    "    fout = open(fout, 'w', encoding=\"utf8\")\n",
    "    for i in range(len(unlabelled_datas)):\n",
    "        for j in range(len(unlabelled_datas[i])):\n",
    "            x = unlabelled_datas[i][j]\n",
    "            y = results[i][j]\n",
    "            fout.write('{} {}\\n'.format(x,y))\n",
    "        fout.write('\\n')\n",
    "    fout.close\n",
    "    print(\"vertibi decoding complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on EN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertibi decoding complete\n"
     ]
    }
   ],
   "source": [
    "data_dict = get_data('EN/train')\n",
    "a = get_transmission_params(data_dict)\n",
    "b = get_modified_emission_params(data_dict,k=3)\n",
    "decode('EN/dev.in','EN/dev.p3.out',a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py EN/dev.out EN/dev.p3.out\n",
    "\n",
    "#Entity in gold data: 226\n",
    "#Entity in prediction: 162\n",
    "\n",
    "#Correct Entity : 104\n",
    "Entity  precision: 0.6420\n",
    "Entity  recall: 0.4602\n",
    "Entity  F: 0.5361\n",
    "\n",
    "#Correct Sentiment : 64\n",
    "Sentiment  precision: 0.3951\n",
    "Sentiment  recall: 0.2832\n",
    "Sentiment  F: 0.3299\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on CN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertibi decoding complete\n"
     ]
    }
   ],
   "source": [
    "data_dict = get_data('CN/train')\n",
    "a = get_transmission_params(data_dict)\n",
    "b = get_modified_emission_params(data_dict,k=3)\n",
    "decode('CN/dev.in','CN/dev.p3.out',a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py CN/dev.out CN/dev.p3.out\n",
    "\n",
    "#Entity in gold data: 362\n",
    "#Entity in prediction: 158\n",
    "\n",
    "#Correct Entity : 64\n",
    "Entity  precision: 0.4051\n",
    "Entity  recall: 0.1768\n",
    "Entity  F: 0.2462\n",
    "\n",
    "#Correct Sentiment : 47\n",
    "Sentiment  precision: 0.2975\n",
    "Sentiment  recall: 0.1298\n",
    "Sentiment  F: 0.1808\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on FR data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertibi decoding complete\n"
     ]
    }
   ],
   "source": [
    "data_dict = get_data('FR/train')\n",
    "a = get_transmission_params(data_dict)\n",
    "b = get_modified_emission_params(data_dict,k=3)\n",
    "decode('FR/dev.in','FR/dev.p3.out',a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py FR/dev.out FR/dev.p3.out\n",
    "\n",
    "#Entity in gold data: 223\n",
    "#Entity in prediction: 166\n",
    "\n",
    "#Correct Entity : 112\n",
    "Entity  precision: 0.6747\n",
    "Entity  recall: 0.5022\n",
    "Entity  F: 0.5758\n",
    "\n",
    "#Correct Sentiment : 72\n",
    "Sentiment  precision: 0.4337\n",
    "Sentiment  recall: 0.3229\n",
    "Sentiment  F: 0.3702\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on SG data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertibi decoding complete\n"
     ]
    }
   ],
   "source": [
    "data_dict = get_data('SG/train')\n",
    "a = get_transmission_params(data_dict)\n",
    "b = get_modified_emission_params(data_dict,k=3)\n",
    "decode('SG/dev.in','SG/dev.p3.out',a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py SG/dev.out SG/dev.p3.out\n",
    "\n",
    "#Entity in gold data: 1382\n",
    "#Entity in prediction: 723\n",
    "\n",
    "#Correct Entity : 386\n",
    "Entity  precision: 0.5339\n",
    "Entity  recall: 0.2793\n",
    "Entity  F: 0.3667\n",
    "\n",
    "#Correct Sentiment : 244\n",
    "Sentiment  precision: 0.3375\n",
    "Sentiment  recall: 0.1766\n",
    "Sentiment  F: 0.2318\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
